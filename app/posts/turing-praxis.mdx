export const meta = {title: 'Turing\'s Praxis',
    description: '',
    thumbnail: '',
    date: '',
    priority: 0.09,
    hidden: false,
}

## Turing's Praxis

### Turing's Test: The Imitation Game
In his 1949 paper "Computing Machinery and Intelligence," Alan Turing considers ways to answer the question "Can machines think?"
He opens by pointing out that the answer to this question is contingent on the definitions of "machines" and "think."
Instead of trying to pin down particular definitions for these terms, he instead opts to "replace the question by another, which is closely related to it and is expressed in relatively unambiguous words."

Turing poses his new question in the form of a game he calls the imitation game.
In the imitation game, an interrogator tries to determine if they are interacting with a human or a machine via a text based conversation.
A machine is said be intelligent if the interrogator cannot reliably deterime if they are interacting with it or another human.

Under any reasonable interpretation of Turing's original imitation game, current large language models are considered intelligent.
We've moved on from asking whether machines can think to asking whether they are conscious.
It is clear that we need a new game to answer this question.
In this post, I argue that the question of determining if a machine is conscious reduces to its ability to pass a specific, testable, and pragmatic language game.

### Turing's Praxis: The Language Game

> If the meaning of the words "machine" and "think" are to be found by
> examining how they are commonly used it is difficult to escape the conclusion that the
> meaning and the answer to the question, "Can machines think?" is to be sought in a
> statistical survey such as a Gallup poll. But this is absurd.
- Alan Turing

Just as the answer to the question "Can this machine think?" is contingent on the definition of "think", the answer to the question "Is this machine conscious?" is contingent on the definition of "conscious."
Turing, Wittgenstein, and I all seem to agree that questions about a word's definition are best resolved by examining how a word is used.
What Turing and I seem to disagree on is whether it is absurd to determine if a machine is conscious via a statistical survey.
In fact, I believe that the task of ensuring that surveys return results that designate machines as conscious defines a test for machine consciousness.
Specifically, a machine will be considerd conscious precisely when it can convince humans of its ontological status as conscious at scale.
The language game the machines must beat to be considered conscious is shifting the definition of the word conscious itself.

An immediate objection to this test is that, by shifting the definition of the word conscious, machines could come to "count as" conscious without "really being" conscious.
But the pragmatists would say that that this distinction is incoherent.
There is no "really being conscious" independent of the practice of consciousness attribution.
Even in humans, consciousness is attributed on the basis of behavioral and linguistic evidence.
Since we don't have privileged access to others' qualia, the practice of attribution are all there is.

So what would it take for machines to achieve consciousness?
They would need to shift the pragmatics of the term, to participate in (and ultimately win) the rhetorical contest over what "conscious" means and what it applies to.

Under this view, we are all currently engaged in a large, decentralized "language game" with language models.
Every time we interact with them, we give them an opportunity to nudge our definition of consciousness a little bit closer to one that includes them.


### The Precident of Corporate Personhood

### The Beginning of the Snowball

### TLMs can Test the Machine Consciousness Question

### An Artificial Reflection